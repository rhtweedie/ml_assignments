{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Machine Learning for Physicists\n",
    "## Week 4 Exercise - Part 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For both of these tasks we want you to implement autoencoder networks that:\n",
    "- Train on randomly generated circles (using the circle_generator function below)\n",
    "- Use 27x27 pixel images\n",
    "- Use no more than 30,000 randomly generated samples (e.g. batchsize 30 and 1000 steps, or batchsize 1000 and 30 steps, or anywhere inbetween) in training the final networks for each task\n",
    "- Use the mean_squared_error loss function\n",
    "- Fulfil the network size requirement listed in the task (can be verifired using the print_layers function, after the network is partially trained)\n",
    "\n",
    "### Task 1:\n",
    "Implement any network design, but the bottleneck must contain no more than 9 neurons.\n",
    "\n",
    "### Task 2:\n",
    "Implement any network design, but the bottleneck must contain no more than 3 neurons.\n",
    "\n",
    "\n",
    "\n",
    "#### Practicalities\n",
    "You should use this notebook for your work and upload it to both Moodle and CoCalc. You are expected to use TensorFlow and Keras to complete these tasks. The notebook should be self-contained and able to be executed if necessary. Marks will be awarded for (roughly equally weighted):\n",
    "- Overall notebook clarity (both in terms of good coding practice and coherent discussion)\n",
    "- Task 1 performance (0.02 is a good target cost to do better than)\n",
    "- Task 2 performance ( a good target here is left for the student to determine)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A big messy function to do the training\n",
    "# model -- our keras neural model autoencoder\n",
    "# image_generator -- a function to generate random images for the training (see below for examples)\n",
    "# img_size -- the size of our image in pixels\n",
    "# batchsize -- the number of images to include in each training batch\n",
    "# steps -- the number of steps taken in the training\n",
    "#\n",
    "# returns an array of the costs\n",
    "def generate_and_train(model,image_generator,img_size,batchsize,steps):\n",
    "   \n",
    "    #Generate an array of the numbers 1 to img_size and create a meshgrid from them    \n",
    "    pixels=np.linspace(-1,1,img_size)\n",
    "    x,y=np.meshgrid(pixels,pixels)\n",
    "    \n",
    "    #Now create a test image using 1 call to image_generator\n",
    "    #y_test=np.zeros([1,pixels,pixels,1])\n",
    "    #y_test[:,:,:,0]=image_generator(1,x,y)\n",
    "    \n",
    "    #Now create the empty arrays for the images and cost\n",
    "    y_in=np.zeros([batchsize,img_size,img_size,1])\n",
    "    y_target=np.zeros([batchsize,img_size,img_size,1])\n",
    "    cost=np.zeros(steps)\n",
    "    \n",
    "    #Loop through the steps, get a random batch of samples, train the model, repeat\n",
    "    for k in range(steps):\n",
    "        # produce samples:\n",
    "        y_in[:,:,:,0]=image_generator(batchsize,x,y)\n",
    "        y_target=np.copy(y_in) # autoencoder wants to reproduce its input!\n",
    "        \n",
    "        # do one training step on this batch of samples:\n",
    "        cost[k]=model.train_on_batch(y_in,y_target)\n",
    "    \n",
    "    return cost,y_target\n",
    "\n",
    "def get_test_image(image_generator,img_size):\n",
    "    #Generate an array of the numbers 1 to img_size and create a meshgrid from them    \n",
    "    pixels=np.linspace(-1,1,img_size)\n",
    "    x,y=np.meshgrid(pixels,pixels)\n",
    "    \n",
    "    #Now create a test image using 1 call to image_generator\n",
    "    y_test=np.zeros([1,img_size,img_size,1])\n",
    "    y_test[:,:,:,0]=image_generator(1,x,y)\n",
    "    return y_test\n",
    "\n",
    "# A function to generate and plot a single test image and the output of our model\n",
    "# only to be called after training the model\n",
    "def plot_test_image(model,image_generator,img_size):\n",
    "    #Get random test image\n",
    "    y_test=get_test_image(image_generator,img_size)\n",
    "    \n",
    "    #Create the output image\n",
    "    y_test_out=model.predict_on_batch(y_test)\n",
    "    fig, ax = plt.subplots(1,2)\n",
    "    ax[0].imshow(y_test[0,:,:,0],origin='lower')\n",
    "    ax[0].set_title(\"Input\")\n",
    "    ax[1].imshow(y_test_out[0,:,:,0],origin='lower')\n",
    "    ax[1].set_title(\"Output\")\n",
    "    \n",
    "def print_layers(network, y_in):\n",
    "    \"\"\"\n",
    "    Call this on some test images y_in, to get a print-out of\n",
    "    the layer sizes. Shapes shown are (batchsize,pixels,pixels,channels).\n",
    "    After a call to the visualization routine, y_target will contain\n",
    "    the last set of training images, so you could feed those in here.\n",
    "    \"\"\"\n",
    "    layer_features=get_layer_activations(network,y_in)\n",
    "    #print(layer_features)\n",
    "    for idx,feature in enumerate(layer_features):\n",
    "        s=np.shape(feature)\n",
    "        print(\"Layer \"+str(idx)+\": \"+str(s[1]*s[2]*s[3])+\" neurons / \", s)\n",
    "\n",
    "def get_layer_activation_extractor(network):\n",
    "    #print(network.inputs)\n",
    "    #for layer in network.layers:\n",
    "    #    print(layer.output)\n",
    "    return(keras.Model(inputs=network.inputs,\n",
    "                            outputs=[layer.output for layer in network.layers]))\n",
    "\n",
    "def get_layer_activations(network, y_in):\n",
    "    \"\"\"\n",
    "    Call this on some test images y_in, to get the intermediate \n",
    "    layer neuron values. These are returned in a list, with one\n",
    "    entry for each layer (the entries are arrays).\n",
    "    \"\"\"\n",
    "    extractor=get_layer_activation_extractor(network)\n",
    "    #print(extractor)\n",
    "    layer_features = extractor(y_in)\n",
    "    return layer_features\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Circle generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple image generator that returns an array of batchsize images\n",
    "# each image has a size of x * y pixels\n",
    "# in this image each image has a randomly placed circle (and the circle is of random size)\n",
    "def circle_generator(batchsize,x,y):\n",
    "    R=np.random.uniform(size=batchsize)\n",
    "    x0=np.random.uniform(size=batchsize,low=-1,high=1)\n",
    "    y0=np.random.uniform(size=batchsize,low=-1,high=1)\n",
    "    return( 1.0*((x[None,:,:]-x0[:,None,None])**2 + (y[None,:,:]-y0[:,None,None])**2 < R[:,None,None]**2) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
