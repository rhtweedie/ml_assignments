{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Machine Learning for Physicists\n",
    "## Week 4 Exercise - Part 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1:\n",
    "Design, implement and test a neural network utilising a single convolutional layer (use as many other non convolutional layers as you need) to classify the MNIST handwritten digits. What is the maximum test accuracry you can achieve using a single convolutional layer?\n",
    "\n",
    "#### Practicalities\n",
    "You should use this notebook for your work and upload it to both Moodle and CoCalc. You are expected to use TensorFlow and Keras to complete these takss. The notebook should be self-contained and able to be executed if necessary. Marks will be awarded for (roughly equally weighted):\n",
    "- Overall notebook clarity (both in terms of good coding practice and coherent discussion)\n",
    "- Network performance (how well does your classifier do?)\n",
    "- Network efficiency (how does your network compare to the optimum networks for this task?)\n",
    "- Network training (do you do a good job of traning your network?)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.layers\n",
    "import keras.datasets.mnist\n",
    "\n",
    "import matplotlib.style #Some style nonsense\n",
    "import matplotlib as mpl #Some more style nonsense\n",
    "\n",
    "\n",
    "#Set default figure size\n",
    "#mpl.rcParams['figure.figsize'] = [12.0, 8.0] #Inches... of course it is inches\n",
    "mpl.rcParams[\"legend.frameon\"] = False\n",
    "mpl.rcParams['figure.dpi']=200 # dots per inch\n",
    "\n",
    "#Useful for debugging problems\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load MNIST data, re-scale and check the shape of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training images: (60000, 28, 28)\n",
      "Length of training set labels: 60000\n",
      "First label: 5\n",
      "Shape of testing images: (10000, 28, 28)\n",
      "Length of testing set labels: 10000\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "mnist = keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# re-scale inputs\n",
    "train_images=train_images/255.0\n",
    "test_images=test_images/255.0\n",
    "\n",
    "# check shape of datasets\n",
    "print(\"Shape of training images:\",train_images.shape)\n",
    "print(\"Length of training set labels:\",len(train_labels))\n",
    "print(\"First label:\",train_labels[0])\n",
    "print(\"Shape of testing images:\",test_images.shape)\n",
    "print(\"Length of testing set labels:\",len(test_labels))\n",
    "\n",
    "image_x = len(train_images[0,:,0])\n",
    "image_y = len(train_images[0,0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define and compile model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(128,activation='relu'))\n",
    "model.add(keras.layers.Dense(15))\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.1556 - accuracy: 0.9542 - val_loss: 0.0630 - val_accuracy: 0.9795\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0524 - accuracy: 0.9840 - val_loss: 0.0559 - val_accuracy: 0.9813\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0339 - accuracy: 0.9893 - val_loss: 0.0434 - val_accuracy: 0.9852\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0217 - accuracy: 0.9931 - val_loss: 0.0496 - val_accuracy: 0.9853\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0151 - accuracy: 0.9951 - val_loss: 0.0454 - val_accuracy: 0.9863\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0107 - accuracy: 0.9966 - val_loss: 0.0391 - val_accuracy: 0.9889\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0085 - accuracy: 0.9973 - val_loss: 0.0490 - val_accuracy: 0.9869\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0065 - accuracy: 0.9979 - val_loss: 0.0529 - val_accuracy: 0.9863\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0058 - accuracy: 0.9981 - val_loss: 0.0516 - val_accuracy: 0.9865\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0038 - accuracy: 0.9987 - val_loss: 0.0858 - val_accuracy: 0.9809\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_images, train_labels, epochs=10, \n",
    "                    validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2:\n",
    "Design, implement and test a neural network utitlising multiple convolutional layers (again use as many other non convolutinal laters as you need) to classify the MNIST handwritten digits. What is the maximum test accuracry you can achieve using as many convolutional layers as you like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "model.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(128,activation='relu'))\n",
    "model.add(keras.layers.Dense(15))\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.1399 - accuracy: 0.9571 - val_loss: 0.0467 - val_accuracy: 0.9861\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0460 - accuracy: 0.9858 - val_loss: 0.0354 - val_accuracy: 0.9891\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.0320 - accuracy: 0.9895 - val_loss: 0.0343 - val_accuracy: 0.9880\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0230 - accuracy: 0.9927 - val_loss: 0.0291 - val_accuracy: 0.9907\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0175 - accuracy: 0.9947 - val_loss: 0.0397 - val_accuracy: 0.9877\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0126 - accuracy: 0.9961 - val_loss: 0.0339 - val_accuracy: 0.9900\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0111 - accuracy: 0.9964 - val_loss: 0.0363 - val_accuracy: 0.9912\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0082 - accuracy: 0.9973 - val_loss: 0.0352 - val_accuracy: 0.9907\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.0073 - accuracy: 0.9976 - val_loss: 0.0465 - val_accuracy: 0.9893\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.0064 - accuracy: 0.9977 - val_loss: 0.0471 - val_accuracy: 0.9879\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_images, train_labels, epochs=10, \n",
    "                    validation_data=(test_images, test_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
