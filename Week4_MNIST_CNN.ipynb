{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Machine Learning for Physicists\n",
    "## Week 4 Exercise - Part 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1:\n",
    "Design, implement and test a neural network utilising a single convolutional layer (use as many other non convolutional layers as you need) to classify the MNIST handwritten digits. What is the maximum test accuracry you can achieve using a single convolutional layer?\n",
    "\n",
    "#### Practicalities\n",
    "You should use this notebook for your work and upload it to both Moodle and CoCalc. You are expected to use TensorFlow and Keras to complete these takss. The notebook should be self-contained and able to be executed if necessary. Marks will be awarded for (roughly equally weighted):\n",
    "- Overall notebook clarity (both in terms of good coding practice and coherent discussion)\n",
    "- Network performance (how well does your classifier do?)\n",
    "- Network efficiency (how does your network compare to the optimum networks for this task?)\n",
    "- Network training (do you do a good job of traning your network?)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-09 15:33:17.819169: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-09 15:33:18.159432: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-02-09 15:33:18.267938: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-09 15:33:18.267966: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-09 15:33:19.654588: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-09 15:33:19.654687: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-09 15:33:19.654695: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.layers\n",
    "import keras.datasets.mnist\n",
    "\n",
    "import matplotlib.style #Some style nonsense\n",
    "import matplotlib as mpl #Some more style nonsense\n",
    "\n",
    "\n",
    "#Set default figure size\n",
    "#mpl.rcParams['figure.figsize'] = [12.0, 8.0] #Inches... of course it is inches\n",
    "mpl.rcParams[\"legend.frameon\"] = False\n",
    "mpl.rcParams['figure.dpi']=200 # dots per inch\n",
    "\n",
    "#Useful for debugging problems\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load MNIST data, re-scale and check the shape of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training images: (60000, 28, 28)\n",
      "Length of training set labels: 60000\n",
      "First label: 5\n",
      "Shape of testing images: (10000, 28, 28)\n",
      "Length of testing set labels: 10000\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "mnist = keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# re-scale inputs\n",
    "train_images=train_images/255.0\n",
    "test_images=test_images/255.0\n",
    "\n",
    "# check shape of datasets\n",
    "print(\"Shape of training images:\",train_images.shape)\n",
    "print(\"Length of training set labels:\",len(train_labels))\n",
    "print(\"First label:\",train_labels[0])\n",
    "print(\"Shape of testing images:\",test_images.shape)\n",
    "print(\"Length of testing set labels:\",len(test_labels))\n",
    "\n",
    "image_x = len(train_images[0,:,0])\n",
    "image_y = len(train_images[0,0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define and compile model, using a single convolutional layer. From testing, I found that a kernel size of 3x3, with the reLU activation function, worked best for the convolutional layer. I reduced the size of the first dense layer from 128 to 30, which only slightly reduced the validation accuracy but increased the execution speed. The number of kernels impacted the performance the most (apart from using reLU over sigmoid for the activation function) so I systematically increased this from 4 to 32 in order to find the maximum performance. The performance increased gradually, with the highest performance achieved at 48 kernels, with little to no reduction in execution time. It would be beneficial to test higher numbers of kernels to observe any leveling-out or reduction in performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(kernel):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Conv2D(kernel, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "    model.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(30, activation = 'relu'))\n",
    "    model.add(keras.layers.Dense(15))\n",
    "\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(train_images, train_labels, epochs=10, \n",
    "                    validation_data=(test_images, test_labels))\n",
    "\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.  8. 12. 16. 20. 24. 28. 32. 36. 40. 44. 48.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-09 15:33:21.807814: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-02-09 15:33:21.807861: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-02-09 15:33:21.807901: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (penguin): /proc/driver/nvidia/version does not exist\n",
      "2023-02-09 15:33:21.808179: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3038 - accuracy: 0.9145 - val_loss: 0.1305 - val_accuracy: 0.9611\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1201 - accuracy: 0.9642 - val_loss: 0.0948 - val_accuracy: 0.9691\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0918 - accuracy: 0.9729 - val_loss: 0.0832 - val_accuracy: 0.9737\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0760 - accuracy: 0.9765 - val_loss: 0.0777 - val_accuracy: 0.9757\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0679 - accuracy: 0.9789 - val_loss: 0.0677 - val_accuracy: 0.9785\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0578 - accuracy: 0.9823 - val_loss: 0.0674 - val_accuracy: 0.9790\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0507 - accuracy: 0.9843 - val_loss: 0.0666 - val_accuracy: 0.9804\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0456 - accuracy: 0.9859 - val_loss: 0.0584 - val_accuracy: 0.9828\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0415 - accuracy: 0.9869 - val_loss: 0.0639 - val_accuracy: 0.9828\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0358 - accuracy: 0.9884 - val_loss: 0.0597 - val_accuracy: 0.9816\n",
      "[0.9610999822616577, 0.9690999984741211, 0.9736999869346619, 0.9757000207901001, 0.9785000085830688, 0.9789999723434448, 0.980400025844574, 0.9828000068664551, 0.9828000068664551, 0.9815999865531921]\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.3160 - accuracy: 0.9076 - val_loss: 0.1643 - val_accuracy: 0.9512\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1298 - accuracy: 0.9616 - val_loss: 0.1093 - val_accuracy: 0.9669\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0953 - accuracy: 0.9715 - val_loss: 0.0991 - val_accuracy: 0.9703\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0752 - accuracy: 0.9767 - val_loss: 0.0737 - val_accuracy: 0.9774\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0632 - accuracy: 0.9804 - val_loss: 0.0688 - val_accuracy: 0.9785\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0515 - accuracy: 0.9839 - val_loss: 0.0668 - val_accuracy: 0.9780\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0459 - accuracy: 0.9855 - val_loss: 0.0586 - val_accuracy: 0.9809\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0392 - accuracy: 0.9877 - val_loss: 0.0669 - val_accuracy: 0.9782\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0340 - accuracy: 0.9896 - val_loss: 0.0562 - val_accuracy: 0.9814\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0295 - accuracy: 0.9906 - val_loss: 0.0575 - val_accuracy: 0.9823\n",
      "[0.951200008392334, 0.9668999910354614, 0.970300018787384, 0.977400004863739, 0.9785000085830688, 0.9779999852180481, 0.98089998960495, 0.9782000184059143, 0.9814000129699707, 0.9822999835014343]\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2492 - accuracy: 0.9278 - val_loss: 0.0976 - val_accuracy: 0.9711\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0897 - accuracy: 0.9735 - val_loss: 0.0747 - val_accuracy: 0.9760\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0636 - accuracy: 0.9806 - val_loss: 0.0717 - val_accuracy: 0.9778\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0503 - accuracy: 0.9849 - val_loss: 0.0599 - val_accuracy: 0.9806\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0416 - accuracy: 0.9876 - val_loss: 0.0548 - val_accuracy: 0.9829\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0339 - accuracy: 0.9898 - val_loss: 0.0517 - val_accuracy: 0.9827\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0278 - accuracy: 0.9914 - val_loss: 0.0528 - val_accuracy: 0.9828\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0223 - accuracy: 0.9933 - val_loss: 0.0508 - val_accuracy: 0.9834\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0192 - accuracy: 0.9940 - val_loss: 0.0542 - val_accuracy: 0.9836\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0155 - accuracy: 0.9950 - val_loss: 0.0533 - val_accuracy: 0.9853\n",
      "[0.9710999727249146, 0.9760000109672546, 0.9778000116348267, 0.9805999994277954, 0.9829000234603882, 0.982699990272522, 0.9828000068664551, 0.9833999872207642, 0.9836000204086304, 0.9853000044822693]\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2565 - accuracy: 0.9261 - val_loss: 0.1092 - val_accuracy: 0.9673\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0894 - accuracy: 0.9735 - val_loss: 0.0692 - val_accuracy: 0.9770\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0647 - accuracy: 0.9800 - val_loss: 0.0621 - val_accuracy: 0.9793\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0520 - accuracy: 0.9847 - val_loss: 0.0571 - val_accuracy: 0.9803\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0424 - accuracy: 0.9868 - val_loss: 0.0607 - val_accuracy: 0.9800\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0352 - accuracy: 0.9893 - val_loss: 0.0586 - val_accuracy: 0.9809\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0299 - accuracy: 0.9910 - val_loss: 0.0539 - val_accuracy: 0.9825\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 8s 5ms/step - loss: 0.0241 - accuracy: 0.9926 - val_loss: 0.0515 - val_accuracy: 0.9844\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0211 - accuracy: 0.9931 - val_loss: 0.0516 - val_accuracy: 0.9835\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0174 - accuracy: 0.9949 - val_loss: 0.0578 - val_accuracy: 0.9841\n",
      "[0.9672999978065491, 0.9769999980926514, 0.9793000221252441, 0.9803000092506409, 0.9800000190734863, 0.98089998960495, 0.9825000166893005, 0.9843999743461609, 0.9835000038146973, 0.9840999841690063]\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2470 - accuracy: 0.9277 - val_loss: 0.0851 - val_accuracy: 0.9754\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0804 - accuracy: 0.9767 - val_loss: 0.0676 - val_accuracy: 0.9785\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0567 - accuracy: 0.9827 - val_loss: 0.0472 - val_accuracy: 0.9846\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0429 - accuracy: 0.9870 - val_loss: 0.0494 - val_accuracy: 0.9837\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0352 - accuracy: 0.9890 - val_loss: 0.0543 - val_accuracy: 0.9818\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0275 - accuracy: 0.9921 - val_loss: 0.0453 - val_accuracy: 0.9860\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0220 - accuracy: 0.9931 - val_loss: 0.0531 - val_accuracy: 0.9841\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0184 - accuracy: 0.9941 - val_loss: 0.0640 - val_accuracy: 0.9813\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0146 - accuracy: 0.9954 - val_loss: 0.0540 - val_accuracy: 0.9841\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 0.0574 - val_accuracy: 0.9846\n",
      "[0.9753999710083008, 0.9785000085830688, 0.9846000075340271, 0.9836999773979187, 0.9818000197410583, 0.9860000014305115, 0.9840999841690063, 0.9812999963760376, 0.9840999841690063, 0.9846000075340271]\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2385 - accuracy: 0.9316 - val_loss: 0.0964 - val_accuracy: 0.9717\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0798 - accuracy: 0.9766 - val_loss: 0.0716 - val_accuracy: 0.9774\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0569 - accuracy: 0.9824 - val_loss: 0.0536 - val_accuracy: 0.9820\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0461 - accuracy: 0.9858 - val_loss: 0.0552 - val_accuracy: 0.9831\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0366 - accuracy: 0.9888 - val_loss: 0.0499 - val_accuracy: 0.9841\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0295 - accuracy: 0.9905 - val_loss: 0.0480 - val_accuracy: 0.9847\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0247 - accuracy: 0.9922 - val_loss: 0.0479 - val_accuracy: 0.9844\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0205 - accuracy: 0.9934 - val_loss: 0.0516 - val_accuracy: 0.9848\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0160 - accuracy: 0.9949 - val_loss: 0.0574 - val_accuracy: 0.9841\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0135 - accuracy: 0.9956 - val_loss: 0.0536 - val_accuracy: 0.9844\n",
      "[0.9717000126838684, 0.977400004863739, 0.9819999933242798, 0.9830999970436096, 0.9840999841690063, 0.9847000241279602, 0.9843999743461609, 0.9847999811172485, 0.9840999841690063, 0.9843999743461609]\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.2339 - accuracy: 0.9288 - val_loss: 0.0862 - val_accuracy: 0.9728\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0800 - accuracy: 0.9765 - val_loss: 0.0604 - val_accuracy: 0.9801\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0564 - accuracy: 0.9827 - val_loss: 0.0609 - val_accuracy: 0.9800\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0446 - accuracy: 0.9866 - val_loss: 0.0469 - val_accuracy: 0.9847\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0354 - accuracy: 0.9892 - val_loss: 0.0598 - val_accuracy: 0.9810\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0288 - accuracy: 0.9909 - val_loss: 0.0538 - val_accuracy: 0.9832\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0219 - accuracy: 0.9933 - val_loss: 0.0545 - val_accuracy: 0.9837\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0186 - accuracy: 0.9940 - val_loss: 0.0587 - val_accuracy: 0.9837\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0145 - accuracy: 0.9954 - val_loss: 0.0548 - val_accuracy: 0.9850\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 0.0579 - val_accuracy: 0.9845\n",
      "[0.9728000164031982, 0.9800999760627747, 0.9800000190734863, 0.9847000241279602, 0.9810000061988831, 0.9832000136375427, 0.9836999773979187, 0.9836999773979187, 0.9850000143051147, 0.984499990940094]\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.2083 - accuracy: 0.9403 - val_loss: 0.0770 - val_accuracy: 0.9745\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0725 - accuracy: 0.9778 - val_loss: 0.0705 - val_accuracy: 0.9779\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0519 - accuracy: 0.9842 - val_loss: 0.0624 - val_accuracy: 0.9795\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0399 - accuracy: 0.9875 - val_loss: 0.0532 - val_accuracy: 0.9832\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0310 - accuracy: 0.9908 - val_loss: 0.0544 - val_accuracy: 0.9828\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0248 - accuracy: 0.9922 - val_loss: 0.0625 - val_accuracy: 0.9809\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0203 - accuracy: 0.9937 - val_loss: 0.0521 - val_accuracy: 0.9845\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0148 - accuracy: 0.9953 - val_loss: 0.0591 - val_accuracy: 0.9833\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0121 - accuracy: 0.9962 - val_loss: 0.0605 - val_accuracy: 0.9846\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0111 - accuracy: 0.9966 - val_loss: 0.0697 - val_accuracy: 0.9821\n",
      "[0.9745000004768372, 0.9779000282287598, 0.9794999957084656, 0.9832000136375427, 0.9828000068664551, 0.98089998960495, 0.984499990940094, 0.983299970626831, 0.9846000075340271, 0.9821000099182129]\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.2066 - accuracy: 0.9392 - val_loss: 0.0875 - val_accuracy: 0.9721\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0668 - accuracy: 0.9801 - val_loss: 0.0522 - val_accuracy: 0.9848\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0483 - accuracy: 0.9848 - val_loss: 0.0512 - val_accuracy: 0.9827\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0378 - accuracy: 0.9881 - val_loss: 0.0488 - val_accuracy: 0.9835\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0289 - accuracy: 0.9908 - val_loss: 0.0448 - val_accuracy: 0.9861\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0225 - accuracy: 0.9929 - val_loss: 0.0517 - val_accuracy: 0.9838\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0177 - accuracy: 0.9943 - val_loss: 0.0523 - val_accuracy: 0.9847\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0143 - accuracy: 0.9954 - val_loss: 0.0489 - val_accuracy: 0.9838\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0116 - accuracy: 0.9962 - val_loss: 0.0614 - val_accuracy: 0.9840\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0103 - accuracy: 0.9968 - val_loss: 0.0530 - val_accuracy: 0.9851\n",
      "[0.972100019454956, 0.9847999811172485, 0.982699990272522, 0.9835000038146973, 0.9861000180244446, 0.9837999939918518, 0.9847000241279602, 0.9837999939918518, 0.984000027179718, 0.9850999712944031]\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.2149 - accuracy: 0.9367 - val_loss: 0.0818 - val_accuracy: 0.9752\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0726 - accuracy: 0.9785 - val_loss: 0.0597 - val_accuracy: 0.9807\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0508 - accuracy: 0.9847 - val_loss: 0.0511 - val_accuracy: 0.9832\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0395 - accuracy: 0.9878 - val_loss: 0.0495 - val_accuracy: 0.9834\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0303 - accuracy: 0.9907 - val_loss: 0.0457 - val_accuracy: 0.9856\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0249 - accuracy: 0.9918 - val_loss: 0.0539 - val_accuracy: 0.9825\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0188 - accuracy: 0.9939 - val_loss: 0.0514 - val_accuracy: 0.9852\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0158 - accuracy: 0.9949 - val_loss: 0.0500 - val_accuracy: 0.9848\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0115 - accuracy: 0.9965 - val_loss: 0.0573 - val_accuracy: 0.9848\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0103 - accuracy: 0.9969 - val_loss: 0.0477 - val_accuracy: 0.9874\n",
      "[0.9751999974250793, 0.9807000160217285, 0.9832000136375427, 0.9833999872207642, 0.9855999946594238, 0.9825000166893005, 0.9851999878883362, 0.9847999811172485, 0.9847999811172485, 0.9873999953269958]\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 15s 7ms/step - loss: 0.2142 - accuracy: 0.9368 - val_loss: 0.0727 - val_accuracy: 0.9773\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0734 - accuracy: 0.9777 - val_loss: 0.0573 - val_accuracy: 0.9811\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0537 - accuracy: 0.9835 - val_loss: 0.0537 - val_accuracy: 0.9819\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0408 - accuracy: 0.9875 - val_loss: 0.0529 - val_accuracy: 0.9843\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0318 - accuracy: 0.9900 - val_loss: 0.0583 - val_accuracy: 0.9807\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0239 - accuracy: 0.9924 - val_loss: 0.0483 - val_accuracy: 0.9842\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0203 - accuracy: 0.9935 - val_loss: 0.0544 - val_accuracy: 0.9847\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0146 - accuracy: 0.9954 - val_loss: 0.0618 - val_accuracy: 0.9830\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0128 - accuracy: 0.9959 - val_loss: 0.0531 - val_accuracy: 0.9862\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0107 - accuracy: 0.9966 - val_loss: 0.0558 - val_accuracy: 0.9854\n",
      "[0.9772999882698059, 0.9811000227928162, 0.9818999767303467, 0.9843000173568726, 0.9807000160217285, 0.9842000007629395, 0.9847000241279602, 0.9829999804496765, 0.9861999750137329, 0.9854000210762024]\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.2063 - accuracy: 0.9382 - val_loss: 0.0832 - val_accuracy: 0.9750\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0716 - accuracy: 0.9786 - val_loss: 0.0583 - val_accuracy: 0.9797\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0523 - accuracy: 0.9843 - val_loss: 0.0641 - val_accuracy: 0.9804\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0399 - accuracy: 0.9875 - val_loss: 0.0538 - val_accuracy: 0.9822\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0309 - accuracy: 0.9901 - val_loss: 0.0525 - val_accuracy: 0.9831\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0249 - accuracy: 0.9920 - val_loss: 0.0543 - val_accuracy: 0.9828\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0181 - accuracy: 0.9945 - val_loss: 0.0524 - val_accuracy: 0.9848\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0150 - accuracy: 0.9955 - val_loss: 0.0529 - val_accuracy: 0.9839\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0119 - accuracy: 0.9962 - val_loss: 0.0640 - val_accuracy: 0.9822\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0085 - accuracy: 0.9973 - val_loss: 0.0618 - val_accuracy: 0.9829\n",
      "[0.9750000238418579, 0.9797000288963318, 0.980400025844574, 0.982200026512146, 0.9830999970436096, 0.9828000068664551, 0.9847999811172485, 0.9839000105857849, 0.982200026512146, 0.9829000234603882]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1280x960 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kernels = np.linspace(4, 48, 12)\n",
    "print(kernels)\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "for kernel in range(len(kernels)):\n",
    "    history = train_model(kernels[kernel])\n",
    "    ax.plot(history.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2:\n",
    "Design, implement and test a neural network utitlising multiple convolutional layers (again use as many other non convolutinal laters as you need) to classify the MNIST handwritten digits. What is the maximum test accuracry you can achieve using as many convolutional layers as you like?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A very high accuracy was achieved with only two convolutional layers, each with 32 and 64 kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "model.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(128,activation='relu'))\n",
    "model.add(keras.layers.Dense(15))\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 18s 9ms/step - loss: 0.1438 - accuracy: 0.9551 - val_loss: 0.0581 - val_accuracy: 0.9812\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0477 - accuracy: 0.9848 - val_loss: 0.0525 - val_accuracy: 0.9828\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0332 - accuracy: 0.9895 - val_loss: 0.0324 - val_accuracy: 0.9893\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0235 - accuracy: 0.9929 - val_loss: 0.0359 - val_accuracy: 0.9890\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0179 - accuracy: 0.9946 - val_loss: 0.0280 - val_accuracy: 0.9903\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0132 - accuracy: 0.9959 - val_loss: 0.0378 - val_accuracy: 0.9886\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.0106 - accuracy: 0.9965 - val_loss: 0.0438 - val_accuracy: 0.9866\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0092 - accuracy: 0.9969 - val_loss: 0.0359 - val_accuracy: 0.9904\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.0079 - accuracy: 0.9972 - val_loss: 0.0444 - val_accuracy: 0.9896\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.0069 - accuracy: 0.9977 - val_loss: 0.0334 - val_accuracy: 0.9923\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_images, train_labels, epochs=10, \n",
    "                    validation_data=(test_images, test_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
